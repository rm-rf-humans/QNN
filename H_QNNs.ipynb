{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rm-rf-humans/QNN/blob/main/H_QNNs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pennylane"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azjMfRfd4fQh",
        "outputId": "537fc6b8-e9c8-41e7-d2f2-64cc4c670236"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pennylane\n",
            "  Downloading PennyLane-0.39.0-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: numpy<2.1 in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from pennylane) (3.4.2)\n",
            "Collecting rustworkx>=0.14.0 (from pennylane)\n",
            "  Downloading rustworkx-0.15.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.7.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from pennylane) (0.10.2)\n",
            "Collecting appdirs (from pennylane)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting autoray>=0.6.11 (from pennylane)\n",
            "  Downloading autoray-0.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from pennylane) (5.5.0)\n",
            "Collecting pennylane-lightning>=0.39 (from pennylane)\n",
            "  Downloading PennyLane_Lightning-0.39.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (26 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pennylane) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pennylane) (4.12.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pennylane) (24.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (2024.12.14)\n",
            "Downloading PennyLane-0.39.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autoray-0.7.0-py3-none-any.whl (930 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m930.0/930.0 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PennyLane_Lightning-0.39.0-cp310-cp310-manylinux_2_28_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rustworkx-0.15.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: appdirs, rustworkx, autoray, pennylane-lightning, pennylane\n",
            "Successfully installed appdirs-1.4.4 autoray-0.7.0 pennylane-0.39.0 pennylane-lightning-0.39.0 rustworkx-0.15.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset, Subset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision import transforms\n",
        "from pennylane import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pennylane as qml\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import shutil\n",
        "import torch\n",
        "import os\n",
        "from IPython.display import display"
      ],
      "metadata": {
        "id": "hK0fPmvqCWIh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BreastCancerDataset(Dataset):\n",
        "    def __init__(self, image_paths, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        image = Image.open(img_path).convert(\"L\")\n",
        "        label = 0 if 'normal' in img_path else 1\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "pzf75IRJah26"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normal_dir = \"normal\"\n",
        "abnormal_dir = \"abnormal\"\n",
        "output_dir = \"output/\"\n",
        "transform = transforms.Compose([transforms.ToTensor()])"
      ],
      "metadata": {
        "id": "guXwYb2naoMZ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_separate_folders(normal_dir, abnormal_dir, output_dir, train_ratio=0.7,\n",
        "                         val_ratio=0.15, test_ratio=0.15, random_state=42):\n",
        "\n",
        "    splits = ['train', 'val', 'test']\n",
        "    classes = ['normal', 'abnormal']\n",
        "\n",
        "    for split in splits:\n",
        "        for cls in classes:\n",
        "            os.makedirs(os.path.join(output_dir, split, cls), exist_ok=True)\n",
        "\n",
        "    results = {\n",
        "        'Class': [],\n",
        "        'Training': [],\n",
        "        'Validation': [],\n",
        "        'Testing': [],\n",
        "        'Total': []\n",
        "    }\n",
        "\n",
        "    for cls, src_dir in zip(classes, [normal_dir, abnormal_dir]):\n",
        "\n",
        "        images = [f for f in os.listdir(src_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
        "        total_images = len(images)\n",
        "\n",
        "\n",
        "        train_images, temp_images = train_test_split(\n",
        "            images,\n",
        "            train_size=train_ratio,\n",
        "            random_state=random_state\n",
        "        )\n",
        "\n",
        "        val_ratio_adjusted = val_ratio / (val_ratio + test_ratio)\n",
        "        val_images, test_images = train_test_split(\n",
        "            temp_images,\n",
        "            train_size=val_ratio_adjusted,\n",
        "            random_state=random_state\n",
        "        )\n",
        "\n",
        "        for img, split_type in zip([train_images, val_images, test_images], splits):\n",
        "            for image_name in img:\n",
        "                shutil.copy2(\n",
        "                    os.path.join(src_dir, image_name),\n",
        "                    os.path.join(output_dir, split_type, cls, image_name)\n",
        "                )\n",
        "\n",
        "        results['Class'].append(cls)\n",
        "        results['Training'].append(len(train_images))\n",
        "        results['Validation'].append(len(val_images))\n",
        "        results['Testing'].append(len(test_images))\n",
        "        results['Total'].append(total_images)\n",
        "\n",
        "    summary_df = pd.DataFrame(results)\n",
        "    display(summary_df)\n",
        "\n",
        "    print(\"\\nSplit Percentages:\")\n",
        "    for split in ['Training', 'Validation', 'Testing']:\n",
        "        total = summary_df[split].sum()\n",
        "        overall_total = summary_df['Total'].sum()\n",
        "        print(f\"{split}: {total} images ({total/overall_total*100:.1f}%)\")\n",
        "\n",
        "    return summary_df"
      ],
      "metadata": {
        "id": "QNamCt6FdCod"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary = split_separate_folders(\n",
        "    normal_dir=normal_dir,\n",
        "    abnormal_dir=abnormal_dir,\n",
        "    output_dir=output_dir\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "JFaQX-Gc29kq",
        "outputId": "bbeb9a29-41fc-41c5-c00a-04d04a358722"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "      Class  Training  Validation  Testing  Total\n",
              "0    normal       350          75       75    500\n",
              "1  abnormal       350          75       75    500"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4d542cc2-1c00-4c5d-bf71-23893a55d8d6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Class</th>\n",
              "      <th>Training</th>\n",
              "      <th>Validation</th>\n",
              "      <th>Testing</th>\n",
              "      <th>Total</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>normal</td>\n",
              "      <td>350</td>\n",
              "      <td>75</td>\n",
              "      <td>75</td>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>abnormal</td>\n",
              "      <td>350</td>\n",
              "      <td>75</td>\n",
              "      <td>75</td>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4d542cc2-1c00-4c5d-bf71-23893a55d8d6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4d542cc2-1c00-4c5d-bf71-23893a55d8d6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4d542cc2-1c00-4c5d-bf71-23893a55d8d6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4bb4be65-e934-41fb-bcac-d37b30f1c2e6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4bb4be65-e934-41fb-bcac-d37b30f1c2e6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4bb4be65-e934-41fb-bcac-d37b30f1c2e6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \")\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"Class\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"abnormal\",\n          \"normal\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Training\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 350,\n        \"max\": 350,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          350\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Validation\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 75,\n        \"max\": 75,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          75\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Testing\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 75,\n        \"max\": 75,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          75\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Total\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 500,\n        \"max\": 500,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          500\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Split Percentages:\n",
            "Training: 700 images (70.0%)\n",
            "Validation: 150 images (15.0%)\n",
            "Testing: 150 images (15.0%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for split in ['train', 'val', 'test']:\n",
        "    for cls in ['normal', 'abnormal']:\n",
        "        path = os.path.join(output_dir, split, cls)\n",
        "        num_images = len([f for f in os.listdir(path) if f.endswith(('.png', '.jpg', '.jpeg'))])"
      ],
      "metadata": {
        "id": "2pAnLeQ32_iN"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MedicalImageDataset(Dataset):\n",
        "\n",
        "    def __init__(self, data_dir, transform=None):\n",
        "\n",
        "        self.data_dir = data_dir\n",
        "        self.transform = transform\n",
        "        self.classes = ['normal', 'abnormal']\n",
        "        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n",
        "\n",
        "        self.images = []\n",
        "        self.labels = []\n",
        "\n",
        "        for cls in self.classes:\n",
        "            class_dir = os.path.join(data_dir, cls)\n",
        "            class_idx = self.class_to_idx[cls]\n",
        "\n",
        "            for img_name in os.listdir(class_dir):\n",
        "                if img_name.endswith(('.png', '.jpg', '.jpeg')):\n",
        "                    self.images.append(os.path.join(class_dir, img_name))\n",
        "                    self.labels.append(class_idx)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        image = Image.open(img_path).convert('L')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "uHBqGzYJ3VoX"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "])\n",
        "\n",
        "val_test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "])"
      ],
      "metadata": {
        "id": "BSQy1HXU3gBT"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_data_loaders(data_dir, batch_size=8, num_workers=4):\n",
        "\n",
        "    train_dataset = MedicalImageDataset(\n",
        "        os.path.join(data_dir, 'train'),\n",
        "        transform=train_transform\n",
        "    )\n",
        "\n",
        "    val_dataset = MedicalImageDataset(\n",
        "        os.path.join(data_dir, 'val'),\n",
        "        transform=val_test_transform\n",
        "    )\n",
        "\n",
        "    test_dataset = MedicalImageDataset(\n",
        "        os.path.join(data_dir, 'test'),\n",
        "        transform=val_test_transform\n",
        "    )\n",
        "\n",
        "    print(f\"Training set size: {len(train_dataset)}\")\n",
        "    print(f\"Validation set size: {len(val_dataset)}\")\n",
        "    print(f\"Test set size: {len(test_dataset)}\")\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    return train_loader, val_loader, test_loader"
      ],
      "metadata": {
        "id": "ByHckTvi3kZT"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"output\"\n",
        "batch_size = 8\n",
        "\n",
        "train_loader, val_loader, test_loader = create_data_loaders(\n",
        "    data_dir=data_dir,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "\n",
        "for images, labels in train_loader:\n",
        "    print(f\"Batch shape: {images.shape}\")\n",
        "    print(f\"Labels shape: {labels.shape}\")\n",
        "    print(f\"Labels: {labels}\")\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gnXqPCPfoFU",
        "outputId": "9e91ccbd-bb48-4e43-be90-9e72c393cbb6"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 700\n",
            "Validation set size: 150\n",
            "Test set size: 150\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch shape: torch.Size([8, 1, 224, 224])\n",
            "Labels shape: torch.Size([8])\n",
            "Labels: tensor([0, 0, 1, 1, 1, 0, 1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ComplexConv2d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
        "        super(ComplexConv2d, self).__init__()\n",
        "        self.real = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
        "        self.imag = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
        "\n",
        "    def forward(self, x):\n",
        "        real, imag = x[:, 0], x[:, 1]\n",
        "        real_out = self.real(real) - self.imag(imag)\n",
        "        imag_out = self.real(imag) + self.imag(real)\n",
        "        return torch.stack([real_out, imag_out], dim=1)\n",
        "\n",
        "class ComplexLinear(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(ComplexLinear, self).__init__()\n",
        "        self.real = nn.Linear(in_features, out_features)\n",
        "        self.imag = nn.Linear(in_features, out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "        real, imag = x[:, 0], x[:, 1]\n",
        "        real_out = self.real(real) - self.imag(imag)\n",
        "        imag_out = self.real(imag) + self.imag(real)\n",
        "        return torch.stack([real_out, imag_out], dim=1)\n",
        "\n",
        "class ComplexActivation(nn.Module):\n",
        "    def __init__(self, activation_func):\n",
        "        super(ComplexActivation, self).__init__()\n",
        "        self.activation_func = activation_func\n",
        "\n",
        "    def forward(self, x):\n",
        "        real, imag = x[:, 0], x[:, 1]\n",
        "        real_out = self.activation_func(real)\n",
        "        imag_out = self.activation_func(imag)\n",
        "        return torch.stack([real_out, imag_out], dim=1)\n",
        "\n",
        "class ComplexMagnitude(nn.Module):\n",
        "    def forward(self, x):\n",
        "        real, imag = x[:, 0], x[:, 1]\n",
        "        return torch.sqrt(real**2 + imag**2)"
      ],
      "metadata": {
        "id": "hNyNSP1XZPwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ComplexModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ComplexModel, self).__init__()\n",
        "\n",
        "        self.conv1 = ComplexConv2d(1, 8, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = ComplexConv2d(8, 16, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "        self.activation = ComplexActivation(nn.ReLU())\n",
        "\n",
        "        self.flattened_size = 16 * 56 * 56\n",
        "        self.fc1 = ComplexLinear(self.flattened_size, 10)\n",
        "        self.fc2 = nn.Linear(10, 2)\n",
        "        self.magnitude = ComplexMagnitude()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.stack([x, torch.zeros_like(x)], dim=1)\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.activation(x)\n",
        "        x = torch.stack([self.pool(x[:, 0]), self.pool(x[:, 1])], dim=1)\n",
        "        x = self.conv2(x)\n",
        "        x = self.activation(x)\n",
        "        x = torch.stack([self.pool(x[:, 0]), self.pool(x[:, 1])], dim=1)\n",
        "\n",
        "        x = x.view(x.size(0), 2, -1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.magnitude(x)\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "metadata": {
        "id": "k0vnQkdoZMpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = ComplexModel().to(device)\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "OttJ5jIef4-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 30\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "        total += target.size(0)\n",
        "        correct += (predicted == target).sum().item()\n",
        "\n",
        "        if batch_idx % 10 == 0:\n",
        "            print(f\"Epoch {epoch+1}/{n_epochs}, Batch {batch_idx}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "    train_loss /= len(train_loader)\n",
        "    train_accuracy = correct / total\n",
        "    print(f\"Training Loss: {train_loss:.4f}, Training Accuracy: {train_accuracy:.4f}\")\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for val_data, val_target in val_loader:\n",
        "            val_data, val_target = val_data.to(device), val_target.to(device)\n",
        "            val_output = model(val_data)\n",
        "            val_loss += criterion(val_output, val_target).item()\n",
        "            _, predicted = torch.max(val_output.data, 1)\n",
        "            total += val_target.size(0)\n",
        "            correct += (predicted == val_target).sum().item()\n",
        "\n",
        "    val_loss /= len(val_loader)\n",
        "    val_accuracy = correct / total\n",
        "    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "print(\"Training complete.\")"
      ],
      "metadata": {
        "id": "YqmYQJgKSmPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "test_loss = 0.0\n",
        "test_correct = 0\n",
        "test_total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for test_data, test_target in test_loader:\n",
        "        test_data, test_target = test_data.to(device), test_target.to(device)\n",
        "        test_output = model(test_data)\n",
        "        test_loss += criterion(test_output, test_target).item()\n",
        "        _, test_predicted = torch.max(test_output.data, 1)\n",
        "        test_total += test_target.size(0)\n",
        "        test_correct += (test_predicted == test_target).sum().item()\n",
        "\n",
        "test_loss /= len(test_loader)\n",
        "test_accuracy = test_correct / test_total\n",
        "\n",
        "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "vzn7rabpY_oP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "val_dataset_new = MedicalImageDataset(\n",
        "    os.path.join(data_dir, 'val'),\n",
        "    transform=val_test_transform\n",
        ")\n",
        "test_single_image(model, val_dataset_new, test_index)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "XGiEHUyohXow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_qubits = 4\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "def circuit(inputs, weights):\n",
        "    qml.templates.AngleEmbedding(inputs, wires=range(n_qubits))\n",
        "    qml.templates.StronglyEntanglingLayers(weights, wires=range(n_qubits))\n",
        "    return [qml.expval(qml.PauliZ(w)) for w in range(n_qubits)]"
      ],
      "metadata": {
        "id": "eT8N7hYg2AX5"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class QNNLayer(nn.Module):\n",
        "    def __init__(self, n_qubits, n_layers):\n",
        "        super(QNNLayer, self).__init__()\n",
        "        self.n_qubits = n_qubits\n",
        "        self.n_layers = n_layers\n",
        "        self.qnode = qml.QNode(circuit, dev, interface=\"torch\")\n",
        "\n",
        "        self.weights = nn.Parameter(torch.randn(n_layers, n_qubits, 3))\n",
        "\n",
        "    def forward(self, x):\n",
        "        q_out = [self.qnode(sample, self.weights) for sample in x]\n",
        "        q_out_tensor = torch.tensor(q_out, dtype=torch.float32, device=x.device)\n",
        "        return q_out_tensor\n"
      ],
      "metadata": {
        "id": "TDFyhfwi2EHm"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class QuantumTransferLearningModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(QuantumTransferLearningModel, self).__init__()\n",
        "\n",
        "        self.feature_extractor = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "        self.fc1 = nn.Linear(256 * 14 * 14, n_qubits)\n",
        "\n",
        "        self.qnn = QNNLayer(n_qubits, 2)\n",
        "\n",
        "        self.fc2 = nn.Linear(n_qubits, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.feature_extractor(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.qnn(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "E77aBSv52HgK"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = QuantumTransferLearningModel().to(device)\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
      ],
      "metadata": {
        "id": "pA4O___f2RW8"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "num_epochs = 30\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    train_loss = running_loss / len(train_loader)\n",
        "    train_accuracy = correct / total\n",
        "\n",
        "    model.eval()\n",
        "    val_running_loss = 0.0\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for val_inputs, val_labels in val_loader:\n",
        "            val_inputs, val_labels = val_inputs.to(device), val_labels.to(device)\n",
        "\n",
        "            val_outputs = model(val_inputs)\n",
        "            val_loss = criterion(val_outputs, val_labels)\n",
        "            val_running_loss += val_loss.item()\n",
        "            _, val_predicted = torch.max(val_outputs.data, 1)\n",
        "            val_total += val_labels.size(0)\n",
        "            val_correct += (val_predicted == val_labels).sum().item()\n",
        "\n",
        "    val_loss_avg = val_running_loss / len(val_loader)\n",
        "    val_accuracy = val_correct / val_total\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
        "          f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, \"\n",
        "          f\"Val Loss: {val_loss_avg:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "    scheduler.step()"
      ],
      "metadata": {
        "id": "pdLQEGO__Ddc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c09aa73e-c90b-470b-fb3c-03f8cc1686ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30, Train Loss: 0.7608, Train Accuracy: 0.5000, Val Loss: 0.7403, Val Accuracy: 0.5000\n"
          ]
        }
      ]
    },
    {
      "source": [
        "model.eval()\n",
        "    test_running_loss = 0.0\n",
        "    test_correct = 0\n",
        "    test_total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for test_inputs, test_labels in test_loader:\n",
        "            test_inputs, test_labels = test_inputs.to(device), test_labels.to(device)\n",
        "\n",
        "            test_outputs = model(test_inputs)\n",
        "\n",
        "            test_loss = criterion(test_outputs, test_labels)\n",
        "\n",
        "            test_running_loss += test_loss.item()\n",
        "            _, test_predicted = torch.max(test_outputs.data, 1)\n",
        "            test_total += test_labels.size(0)\n",
        "            test_correct += (test_predicted == test_labels).sum().item()\n",
        "\n",
        "    test_loss_avg = test_running_loss / len(test_loader)\n",
        "    test_accuracy = test_correct / test_total\n",
        "\n",
        "    print(f\"Test Loss: {test_loss_avg:.4f}, Test Accuracy: {test_accuracy:.4f}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "Niu8f9g1_lHc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
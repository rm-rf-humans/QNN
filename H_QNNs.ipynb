{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rm-rf-humans/QNN/blob/main/H_QNNs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pennylane"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azjMfRfd4fQh",
        "outputId": "537fc6b8-e9c8-41e7-d2f2-64cc4c670236"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pennylane\n",
            "  Downloading PennyLane-0.39.0-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: numpy<2.1 in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from pennylane) (3.4.2)\n",
            "Collecting rustworkx>=0.14.0 (from pennylane)\n",
            "  Downloading rustworkx-0.15.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.7.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from pennylane) (0.10.2)\n",
            "Collecting appdirs (from pennylane)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting autoray>=0.6.11 (from pennylane)\n",
            "  Downloading autoray-0.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from pennylane) (5.5.0)\n",
            "Collecting pennylane-lightning>=0.39 (from pennylane)\n",
            "  Downloading PennyLane_Lightning-0.39.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (26 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pennylane) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pennylane) (4.12.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pennylane) (24.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (2024.12.14)\n",
            "Downloading PennyLane-0.39.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autoray-0.7.0-py3-none-any.whl (930 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m930.0/930.0 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PennyLane_Lightning-0.39.0-cp310-cp310-manylinux_2_28_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rustworkx-0.15.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: appdirs, rustworkx, autoray, pennylane-lightning, pennylane\n",
            "Successfully installed appdirs-1.4.4 autoray-0.7.0 pennylane-0.39.0 pennylane-lightning-0.39.0 rustworkx-0.15.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset, Subset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision import transforms\n",
        "from pennylane import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pennylane as qml\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import shutil\n",
        "import torch\n",
        "import os\n",
        "from IPython.display import display"
      ],
      "metadata": {
        "id": "hK0fPmvqCWIh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BreastCancerDataset(Dataset):\n",
        "    def __init__(self, image_paths, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        image = Image.open(img_path).convert(\"L\")\n",
        "        label = 0 if 'normal' in img_path else 1\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "pzf75IRJah26"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normal_dir = \"normal\"\n",
        "abnormal_dir = \"abnormal\"\n",
        "output_dir = \"output/\"\n",
        "transform = transforms.Compose([transforms.ToTensor()])"
      ],
      "metadata": {
        "id": "guXwYb2naoMZ"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_separate_folders(normal_dir, abnormal_dir, output_dir, train_ratio=0.7,\n",
        "                         val_ratio=0.15, test_ratio=0.15, random_state=42):\n",
        "\n",
        "    splits = ['train', 'val', 'test']\n",
        "    classes = ['normal', 'abnormal']\n",
        "\n",
        "    for split in splits:\n",
        "        for cls in classes:\n",
        "            os.makedirs(os.path.join(output_dir, split, cls), exist_ok=True)\n",
        "\n",
        "    results = {\n",
        "        'Class': [],\n",
        "        'Training': [],\n",
        "        'Validation': [],\n",
        "        'Testing': [],\n",
        "        'Total': []\n",
        "    }\n",
        "\n",
        "    for cls, src_dir in zip(classes, [normal_dir, abnormal_dir]):\n",
        "\n",
        "        images = [f for f in os.listdir(src_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
        "        total_images = len(images)\n",
        "\n",
        "\n",
        "        train_images, temp_images = train_test_split(\n",
        "            images,\n",
        "            train_size=train_ratio,\n",
        "            random_state=random_state\n",
        "        )\n",
        "\n",
        "        val_ratio_adjusted = val_ratio / (val_ratio + test_ratio)\n",
        "        val_images, test_images = train_test_split(\n",
        "            temp_images,\n",
        "            train_size=val_ratio_adjusted,\n",
        "            random_state=random_state\n",
        "        )\n",
        "\n",
        "        for img, split_type in zip([train_images, val_images, test_images], splits):\n",
        "            for image_name in img:\n",
        "                shutil.copy2(\n",
        "                    os.path.join(src_dir, image_name),\n",
        "                    os.path.join(output_dir, split_type, cls, image_name)\n",
        "                )\n",
        "\n",
        "        results['Class'].append(cls)\n",
        "        results['Training'].append(len(train_images))\n",
        "        results['Validation'].append(len(val_images))\n",
        "        results['Testing'].append(len(test_images))\n",
        "        results['Total'].append(total_images)\n",
        "\n",
        "    summary_df = pd.DataFrame(results)\n",
        "    display(summary_df)\n",
        "\n",
        "    print(\"\\nSplit Percentages:\")\n",
        "    for split in ['Training', 'Validation', 'Testing']:\n",
        "        total = summary_df[split].sum()\n",
        "        overall_total = summary_df['Total'].sum()\n",
        "        print(f\"{split}: {total} images ({total/overall_total*100:.1f}%)\")\n",
        "\n",
        "    return summary_df"
      ],
      "metadata": {
        "id": "QNamCt6FdCod"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary = split_separate_folders(\n",
        "    normal_dir=normal_dir,\n",
        "    abnormal_dir=abnormal_dir,\n",
        "    output_dir=output_dir\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "JFaQX-Gc29kq",
        "outputId": "f6ae9904-9799-4bfc-aad1-b99feb4d8ae3"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "      Class  Training  Validation  Testing  Total\n",
              "0    normal       350          75       75    500\n",
              "1  abnormal       350          75       75    500"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a4370dc9-1df7-45d0-9829-2be7cee2d1f3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Class</th>\n",
              "      <th>Training</th>\n",
              "      <th>Validation</th>\n",
              "      <th>Testing</th>\n",
              "      <th>Total</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>normal</td>\n",
              "      <td>350</td>\n",
              "      <td>75</td>\n",
              "      <td>75</td>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>abnormal</td>\n",
              "      <td>350</td>\n",
              "      <td>75</td>\n",
              "      <td>75</td>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a4370dc9-1df7-45d0-9829-2be7cee2d1f3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a4370dc9-1df7-45d0-9829-2be7cee2d1f3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a4370dc9-1df7-45d0-9829-2be7cee2d1f3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-da846718-8dff-457a-9c95-f56332d6925d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-da846718-8dff-457a-9c95-f56332d6925d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-da846718-8dff-457a-9c95-f56332d6925d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \")\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"Class\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"abnormal\",\n          \"normal\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Training\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 350,\n        \"max\": 350,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          350\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Validation\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 75,\n        \"max\": 75,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          75\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Testing\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 75,\n        \"max\": 75,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          75\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Total\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 500,\n        \"max\": 500,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          500\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Split Percentages:\n",
            "Training: 700 images (70.0%)\n",
            "Validation: 150 images (15.0%)\n",
            "Testing: 150 images (15.0%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for split in ['train', 'val', 'test']:\n",
        "    for cls in ['normal', 'abnormal']:\n",
        "        path = os.path.join(output_dir, split, cls)\n",
        "        num_images = len([f for f in os.listdir(path) if f.endswith(('.png', '.jpg', '.jpeg'))])"
      ],
      "metadata": {
        "id": "2pAnLeQ32_iN"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MedicalImageDataset(Dataset):\n",
        "\n",
        "    def __init__(self, data_dir, transform=None):\n",
        "\n",
        "        self.data_dir = data_dir\n",
        "        self.transform = transform\n",
        "        self.classes = ['normal', 'abnormal']\n",
        "        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n",
        "\n",
        "        self.images = []\n",
        "        self.labels = []\n",
        "\n",
        "        for cls in self.classes:\n",
        "            class_dir = os.path.join(data_dir, cls)\n",
        "            class_idx = self.class_to_idx[cls]\n",
        "\n",
        "            for img_name in os.listdir(class_dir):\n",
        "                if img_name.endswith(('.png', '.jpg', '.jpeg')):\n",
        "                    self.images.append(os.path.join(class_dir, img_name))\n",
        "                    self.labels.append(class_idx)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        image = Image.open(img_path).convert('L')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "uHBqGzYJ3VoX"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "])\n",
        "\n",
        "val_test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "])"
      ],
      "metadata": {
        "id": "BSQy1HXU3gBT"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_data_loaders(data_dir, batch_size=8, num_workers=2):\n",
        "\n",
        "    train_dataset = MedicalImageDataset(\n",
        "        os.path.join(data_dir, 'train'),\n",
        "        transform=train_transform\n",
        "    )\n",
        "\n",
        "    val_dataset = MedicalImageDataset(\n",
        "        os.path.join(data_dir, 'val'),\n",
        "        transform=val_test_transform\n",
        "    )\n",
        "\n",
        "    test_dataset = MedicalImageDataset(\n",
        "        os.path.join(data_dir, 'test'),\n",
        "        transform=val_test_transform\n",
        "    )\n",
        "\n",
        "    print(f\"Training set size: {len(train_dataset)}\")\n",
        "    print(f\"Validation set size: {len(val_dataset)}\")\n",
        "    print(f\"Test set size: {len(test_dataset)}\")\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    return train_loader, val_loader, test_loader"
      ],
      "metadata": {
        "id": "ByHckTvi3kZT"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"output\"\n",
        "batch_size = 8\n",
        "\n",
        "train_loader, val_loader, test_loader = create_data_loaders(\n",
        "    data_dir=data_dir,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "\n",
        "for images, labels in train_loader:\n",
        "    print(f\"Batch shape: {images.shape}\")\n",
        "    print(f\"Labels shape: {labels.shape}\")\n",
        "    print(f\"Labels: {labels}\")\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gnXqPCPfoFU",
        "outputId": "b6d6d366-2058-4d93-ae53-ffd3206b351b"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 700\n",
            "Validation set size: 150\n",
            "Test set size: 150\n",
            "Batch shape: torch.Size([8, 1, 224, 224])\n",
            "Labels shape: torch.Size([8])\n",
            "Labels: tensor([0, 0, 1, 1, 1, 0, 1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ComplexConv2d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
        "        super(ComplexConv2d, self).__init__()\n",
        "        self.real = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
        "        self.imag = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
        "\n",
        "    def forward(self, x):\n",
        "        real, imag = x[:, 0], x[:, 1]\n",
        "        real_out = self.real(real) - self.imag(imag)\n",
        "        imag_out = self.real(imag) + self.imag(real)\n",
        "        return torch.stack([real_out, imag_out], dim=1)\n",
        "\n",
        "class ComplexLinear(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(ComplexLinear, self).__init__()\n",
        "        self.real = nn.Linear(in_features, out_features)\n",
        "        self.imag = nn.Linear(in_features, out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "        real, imag = x[:, 0], x[:, 1]\n",
        "        real_out = self.real(real) - self.imag(imag)\n",
        "        imag_out = self.real(imag) + self.imag(real)\n",
        "        return torch.stack([real_out, imag_out], dim=1)\n",
        "\n",
        "class ComplexActivation(nn.Module):\n",
        "    def __init__(self, activation_func):\n",
        "        super(ComplexActivation, self).__init__()\n",
        "        self.activation_func = activation_func\n",
        "\n",
        "    def forward(self, x):\n",
        "        real, imag = x[:, 0], x[:, 1]\n",
        "        real_out = self.activation_func(real)\n",
        "        imag_out = self.activation_func(imag)\n",
        "        return torch.stack([real_out, imag_out], dim=1)\n",
        "\n",
        "class ComplexMagnitude(nn.Module):\n",
        "    def forward(self, x):\n",
        "        real, imag = x[:, 0], x[:, 1]\n",
        "        return torch.sqrt(real**2 + imag**2)"
      ],
      "metadata": {
        "id": "hNyNSP1XZPwt"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ComplexModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ComplexModel, self).__init__()\n",
        "\n",
        "        self.conv1 = ComplexConv2d(1, 8, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = ComplexConv2d(8, 16, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "        self.activation = ComplexActivation(nn.ReLU())\n",
        "\n",
        "        self.flattened_size = 16 * 56 * 56\n",
        "        self.fc1 = ComplexLinear(self.flattened_size, 10)\n",
        "        self.fc2 = nn.Linear(10, 2)\n",
        "        self.magnitude = ComplexMagnitude()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.stack([x, torch.zeros_like(x)], dim=1)\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.activation(x)\n",
        "        x = torch.stack([self.pool(x[:, 0]), self.pool(x[:, 1])], dim=1)\n",
        "        x = self.conv2(x)\n",
        "        x = self.activation(x)\n",
        "        x = torch.stack([self.pool(x[:, 0]), self.pool(x[:, 1])], dim=1)\n",
        "\n",
        "        x = x.view(x.size(0), 2, -1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.magnitude(x)\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "metadata": {
        "id": "k0vnQkdoZMpi"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = ComplexModel().to(device)\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "OttJ5jIef4-I"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 30\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "        total += target.size(0)\n",
        "        correct += (predicted == target).sum().item()\n",
        "\n",
        "        if batch_idx % 10 == 0:\n",
        "            print(f\"Epoch {epoch+1}/{n_epochs}, Batch {batch_idx}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "    train_loss /= len(train_loader)\n",
        "    train_accuracy = correct / total\n",
        "    print(f\"Training Loss: {train_loss:.4f}, Training Accuracy: {train_accuracy:.4f}\")\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for val_data, val_target in val_loader:\n",
        "            val_data, val_target = val_data.to(device), val_target.to(device)\n",
        "            val_output = model(val_data)\n",
        "            val_loss += criterion(val_output, val_target).item()\n",
        "            _, predicted = torch.max(val_output.data, 1)\n",
        "            total += val_target.size(0)\n",
        "            correct += (predicted == val_target).sum().item()\n",
        "\n",
        "    val_loss /= len(val_loader)\n",
        "    val_accuracy = correct / total\n",
        "    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "print(\"Training complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqmYQJgKSmPj",
        "outputId": "da6f6f5f-121d-4917-f0be-d6ef3dd1ca48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30, Batch 0, Loss: 0.7351\n",
            "Epoch 1/30, Batch 10, Loss: 1.9024\n",
            "Epoch 1/30, Batch 20, Loss: 0.6068\n",
            "Epoch 1/30, Batch 30, Loss: 0.7016\n",
            "Epoch 1/30, Batch 40, Loss: 0.5153\n",
            "Epoch 1/30, Batch 50, Loss: 0.4010\n",
            "Epoch 1/30, Batch 60, Loss: 0.4552\n",
            "Epoch 1/30, Batch 70, Loss: 0.2744\n",
            "Epoch 1/30, Batch 80, Loss: 0.2333\n",
            "Training Loss: 1.0460, Training Accuracy: 0.6986\n",
            "Validation Loss: 0.2314, Validation Accuracy: 0.9800\n",
            "Epoch 2/30, Batch 0, Loss: 0.3222\n",
            "Epoch 2/30, Batch 10, Loss: 0.2262\n",
            "Epoch 2/30, Batch 20, Loss: 0.1899\n",
            "Epoch 2/30, Batch 30, Loss: 0.1877\n",
            "Epoch 2/30, Batch 40, Loss: 0.1237\n",
            "Epoch 2/30, Batch 50, Loss: 0.0490\n",
            "Epoch 2/30, Batch 60, Loss: 0.0787\n",
            "Epoch 2/30, Batch 70, Loss: 0.0189\n",
            "Epoch 2/30, Batch 80, Loss: 0.0906\n",
            "Training Loss: 0.2003, Training Accuracy: 0.9314\n",
            "Validation Loss: 0.0583, Validation Accuracy: 0.9800\n",
            "Epoch 3/30, Batch 0, Loss: 0.0382\n",
            "Epoch 3/30, Batch 10, Loss: 0.0187\n",
            "Epoch 3/30, Batch 20, Loss: 0.0110\n",
            "Epoch 3/30, Batch 30, Loss: 0.0724\n",
            "Epoch 3/30, Batch 40, Loss: 0.0987\n",
            "Epoch 3/30, Batch 50, Loss: 0.0480\n",
            "Epoch 3/30, Batch 60, Loss: 0.0338\n",
            "Epoch 3/30, Batch 70, Loss: 0.0120\n",
            "Epoch 3/30, Batch 80, Loss: 0.0058\n",
            "Training Loss: 0.0669, Training Accuracy: 0.9743\n",
            "Validation Loss: 0.0101, Validation Accuracy: 1.0000\n",
            "Epoch 4/30, Batch 0, Loss: 0.0184\n",
            "Epoch 4/30, Batch 10, Loss: 0.0024\n",
            "Epoch 4/30, Batch 20, Loss: 0.0108\n",
            "Epoch 4/30, Batch 30, Loss: 0.0132\n",
            "Epoch 4/30, Batch 40, Loss: 0.0472\n",
            "Epoch 4/30, Batch 50, Loss: 0.0036\n",
            "Epoch 4/30, Batch 60, Loss: 0.0159\n",
            "Epoch 4/30, Batch 70, Loss: 0.0098\n",
            "Epoch 4/30, Batch 80, Loss: 0.0057\n",
            "Training Loss: 0.0410, Training Accuracy: 0.9886\n",
            "Validation Loss: 0.0050, Validation Accuracy: 1.0000\n",
            "Epoch 5/30, Batch 0, Loss: 0.0027\n",
            "Epoch 5/30, Batch 10, Loss: 0.0012\n",
            "Epoch 5/30, Batch 20, Loss: 0.0098\n",
            "Epoch 5/30, Batch 30, Loss: 0.0027\n",
            "Epoch 5/30, Batch 40, Loss: 0.0036\n",
            "Epoch 5/30, Batch 50, Loss: 0.0088\n",
            "Epoch 5/30, Batch 60, Loss: 0.0178\n",
            "Epoch 5/30, Batch 70, Loss: 0.0005\n",
            "Epoch 5/30, Batch 80, Loss: 0.0034\n",
            "Training Loss: 0.0134, Training Accuracy: 0.9986\n",
            "Validation Loss: 0.0052, Validation Accuracy: 1.0000\n",
            "Epoch 6/30, Batch 0, Loss: 0.0004\n",
            "Epoch 6/30, Batch 10, Loss: 0.0177\n",
            "Epoch 6/30, Batch 20, Loss: 0.0139\n",
            "Epoch 6/30, Batch 30, Loss: 0.0135\n",
            "Epoch 6/30, Batch 40, Loss: 0.0030\n",
            "Epoch 6/30, Batch 50, Loss: 0.0415\n",
            "Epoch 6/30, Batch 60, Loss: 0.0425\n",
            "Epoch 6/30, Batch 70, Loss: 0.0008\n",
            "Epoch 6/30, Batch 80, Loss: 0.0012\n",
            "Training Loss: 0.0414, Training Accuracy: 0.9886\n",
            "Validation Loss: 0.0018, Validation Accuracy: 1.0000\n",
            "Epoch 7/30, Batch 0, Loss: 0.0004\n",
            "Epoch 7/30, Batch 10, Loss: 0.0005\n",
            "Epoch 7/30, Batch 20, Loss: 0.0033\n",
            "Epoch 7/30, Batch 30, Loss: 0.0018\n",
            "Epoch 7/30, Batch 40, Loss: 0.0003\n",
            "Epoch 7/30, Batch 50, Loss: 0.0002\n",
            "Epoch 7/30, Batch 60, Loss: 0.0000\n",
            "Epoch 7/30, Batch 70, Loss: 0.0008\n",
            "Epoch 7/30, Batch 80, Loss: 0.0004\n",
            "Training Loss: 0.0023, Training Accuracy: 1.0000\n",
            "Validation Loss: 0.0185, Validation Accuracy: 0.9933\n",
            "Epoch 8/30, Batch 0, Loss: 0.0011\n",
            "Epoch 8/30, Batch 10, Loss: 0.0033\n",
            "Epoch 8/30, Batch 20, Loss: 0.0020\n",
            "Epoch 8/30, Batch 30, Loss: 0.0047\n",
            "Epoch 8/30, Batch 40, Loss: 0.0040\n",
            "Epoch 8/30, Batch 50, Loss: 0.0005\n",
            "Epoch 8/30, Batch 60, Loss: 0.0123\n",
            "Epoch 8/30, Batch 70, Loss: 0.0143\n",
            "Epoch 8/30, Batch 80, Loss: 0.0052\n",
            "Training Loss: 0.0045, Training Accuracy: 1.0000\n",
            "Validation Loss: 0.0008, Validation Accuracy: 1.0000\n",
            "Epoch 9/30, Batch 0, Loss: 0.0002\n",
            "Epoch 9/30, Batch 10, Loss: 0.0004\n",
            "Epoch 9/30, Batch 20, Loss: 0.0002\n",
            "Epoch 9/30, Batch 30, Loss: 0.0115\n",
            "Epoch 9/30, Batch 40, Loss: 0.0397\n",
            "Epoch 9/30, Batch 50, Loss: 0.0147\n",
            "Epoch 9/30, Batch 60, Loss: 0.0006\n",
            "Epoch 9/30, Batch 70, Loss: 0.0036\n",
            "Epoch 9/30, Batch 80, Loss: 0.0003\n",
            "Training Loss: 0.0018, Training Accuracy: 1.0000\n",
            "Validation Loss: 0.0004, Validation Accuracy: 1.0000\n",
            "Epoch 10/30, Batch 0, Loss: 0.0001\n",
            "Epoch 10/30, Batch 10, Loss: 0.0007\n",
            "Epoch 10/30, Batch 20, Loss: 0.0023\n",
            "Epoch 10/30, Batch 30, Loss: 0.0001\n",
            "Epoch 10/30, Batch 40, Loss: 0.0002\n",
            "Epoch 10/30, Batch 50, Loss: 0.0001\n",
            "Epoch 10/30, Batch 60, Loss: 0.0052\n",
            "Epoch 10/30, Batch 70, Loss: 0.0014\n",
            "Epoch 10/30, Batch 80, Loss: 0.0004\n",
            "Training Loss: 0.0010, Training Accuracy: 1.0000\n",
            "Validation Loss: 0.0003, Validation Accuracy: 1.0000\n",
            "Epoch 11/30, Batch 0, Loss: 0.0002\n",
            "Epoch 11/30, Batch 10, Loss: 0.0003\n",
            "Epoch 11/30, Batch 20, Loss: 0.0002\n",
            "Epoch 11/30, Batch 30, Loss: 0.0000\n",
            "Epoch 11/30, Batch 40, Loss: 0.0007\n",
            "Epoch 11/30, Batch 50, Loss: 0.0000\n",
            "Epoch 11/30, Batch 60, Loss: 0.0330\n",
            "Epoch 11/30, Batch 70, Loss: 0.0116\n",
            "Epoch 11/30, Batch 80, Loss: 0.0001\n",
            "Training Loss: 0.0012, Training Accuracy: 1.0000\n",
            "Validation Loss: 0.0009, Validation Accuracy: 1.0000\n",
            "Epoch 12/30, Batch 0, Loss: 0.0000\n",
            "Epoch 12/30, Batch 10, Loss: 0.0016\n",
            "Epoch 12/30, Batch 20, Loss: 0.0001\n",
            "Epoch 12/30, Batch 30, Loss: 0.0001\n",
            "Epoch 12/30, Batch 40, Loss: 0.0002\n",
            "Epoch 12/30, Batch 50, Loss: 0.0002\n",
            "Epoch 12/30, Batch 60, Loss: 0.0007\n",
            "Epoch 12/30, Batch 70, Loss: 0.0000\n",
            "Epoch 12/30, Batch 80, Loss: 0.0005\n",
            "Training Loss: 0.0006, Training Accuracy: 1.0000\n",
            "Validation Loss: 0.0002, Validation Accuracy: 1.0000\n",
            "Epoch 13/30, Batch 0, Loss: 0.0001\n",
            "Epoch 13/30, Batch 10, Loss: 0.0000\n",
            "Epoch 13/30, Batch 20, Loss: 0.0001\n",
            "Epoch 13/30, Batch 30, Loss: 0.0001\n",
            "Epoch 13/30, Batch 40, Loss: 0.0000\n",
            "Epoch 13/30, Batch 50, Loss: 0.0000\n",
            "Epoch 13/30, Batch 60, Loss: 0.0005\n",
            "Epoch 13/30, Batch 70, Loss: 0.0000\n",
            "Epoch 13/30, Batch 80, Loss: 0.0001\n",
            "Training Loss: 0.0003, Training Accuracy: 1.0000\n",
            "Validation Loss: 0.0001, Validation Accuracy: 1.0000\n",
            "Epoch 14/30, Batch 0, Loss: 0.0001\n",
            "Epoch 14/30, Batch 10, Loss: 0.0002\n",
            "Epoch 14/30, Batch 20, Loss: 0.0001\n",
            "Epoch 14/30, Batch 30, Loss: 0.0002\n",
            "Epoch 14/30, Batch 40, Loss: 0.0002\n",
            "Epoch 14/30, Batch 50, Loss: 0.0000\n",
            "Epoch 14/30, Batch 60, Loss: 0.0001\n",
            "Epoch 14/30, Batch 70, Loss: 0.0002\n",
            "Epoch 14/30, Batch 80, Loss: 0.0001\n",
            "Training Loss: 0.0003, Training Accuracy: 1.0000\n",
            "Validation Loss: 0.0001, Validation Accuracy: 1.0000\n",
            "Epoch 15/30, Batch 0, Loss: 0.0001\n",
            "Epoch 15/30, Batch 10, Loss: 0.0001\n",
            "Epoch 15/30, Batch 20, Loss: 0.0001\n",
            "Epoch 15/30, Batch 30, Loss: 0.0001\n",
            "Epoch 15/30, Batch 40, Loss: 0.0001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "test_loss = 0.0\n",
        "test_correct = 0\n",
        "test_total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for test_data, test_target in test_loader:\n",
        "        test_data, test_target = test_data.to(device), test_target.to(device)\n",
        "        test_output = model(test_data)\n",
        "        test_loss += criterion(test_output, test_target).item()\n",
        "        _, test_predicted = torch.max(test_output.data, 1)\n",
        "        test_total += test_target.size(0)\n",
        "        test_correct += (test_predicted == test_target).sum().item()\n",
        "\n",
        "test_loss /= len(test_loader)\n",
        "test_accuracy = test_correct / test_total\n",
        "\n",
        "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "vzn7rabpY_oP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "val_dataset_new = MedicalImageDataset(\n",
        "    os.path.join(data_dir, 'val'),\n",
        "    transform=val_test_transform\n",
        ")\n",
        "test_single_image(model, val_dataset_new, test_index)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "XGiEHUyohXow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassicalFeatureExtractor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ClassicalFeatureExtractor, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        self.fc1 = nn.Linear(64 * 56 * 56, 128)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 56 * 56)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        return x\n",
        "\n",
        "dev = qml.device(\"default.qubit\", wires=4)\n",
        "\n",
        "@qml.qnode(dev, interface='torch')\n",
        "def quantum_circuit(inputs, weights):\n",
        "    qml.templates.AngleEmbedding(inputs, wires=range(4))\n",
        "    qml.templates.BasicEntanglerLayers(weights, wires=range(4))\n",
        "    return [qml.expval(qml.PauliZ(i)) for i in range(4)]\n",
        "\n",
        "class VQC(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VQC, self).__init__()\n",
        "        self.weight_shapes = {\"weights\": (6, 4)}\n",
        "        self.qlayer = qml.qnn.TorchLayer(quantum_circuit, self.weight_shapes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.qlayer(x)\n",
        "\n",
        "class HybridModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(HybridModel, self).__init__()\n",
        "        self.feature_extractor = ClassicalFeatureExtractor()\n",
        "        self.fc = nn.Linear(128, 4)\n",
        "        self.vqc = VQC()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.feature_extractor(x)\n",
        "        x = self.fc(x)\n",
        "        x = self.vqc(x)\n",
        "        return x\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = HybridModel().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "\n",
        "num_epochs = 30\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    train_loss = running_loss / len(train_loader)\n",
        "    train_accuracy = correct / total\n",
        "\n",
        "    model.eval()\n",
        "    val_running_loss = 0.0\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for val_inputs, val_labels in val_loader:\n",
        "            val_inputs, val_labels = val_inputs.to(device), val_labels.to(device)\n",
        "\n",
        "            val_outputs = model(val_inputs)\n",
        "            val_loss = criterion(val_outputs, val_labels)\n",
        "            val_running_loss += val_loss.item()\n",
        "            _, val_predicted = torch.max(val_outputs.data, 1)\n",
        "            val_total += val_labels.size(0)\n",
        "            val_correct += (val_predicted == val_labels).sum().item()\n",
        "\n",
        "    val_loss_avg = val_running_loss / len(val_loader)\n",
        "    val_accuracy = val_correct / val_total\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
        "          f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, \"\n",
        "          f\"Val Loss: {val_loss_avg:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "    if val_loss_avg < best_val_loss:\n",
        "        best_val_loss = val_loss_avg\n",
        "        torch.save(model.state_dict(), 'best_model.pth')\n",
        "\n",
        "    scheduler.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVVpksUYNODQ",
        "outputId": "f7097b6c-069b-47c1-848e-ec74762d3356"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30, Train Loss: 1.2669, Train Accuracy: 0.3986, Val Loss: 1.0688, Val Accuracy: 0.5867\n",
            "Epoch 2/30, Train Loss: 1.0550, Train Accuracy: 0.6057, Val Loss: 1.0104, Val Accuracy: 0.7067\n",
            "Epoch 3/30, Train Loss: 0.9989, Train Accuracy: 0.6786, Val Loss: 0.9860, Val Accuracy: 0.7933\n",
            "Epoch 4/30, Train Loss: 0.9131, Train Accuracy: 0.8300, Val Loss: 0.8247, Val Accuracy: 0.9667\n",
            "Epoch 5/30, Train Loss: 0.7583, Train Accuracy: 0.9614, Val Loss: 0.6527, Val Accuracy: 0.9867\n",
            "Epoch 6/30, Train Loss: 0.6082, Train Accuracy: 0.9900, Val Loss: 0.5473, Val Accuracy: 1.0000\n",
            "Epoch 7/30, Train Loss: 0.5277, Train Accuracy: 0.9971, Val Loss: 0.4798, Val Accuracy: 1.0000\n",
            "Epoch 8/30, Train Loss: 0.4700, Train Accuracy: 1.0000, Val Loss: 0.4346, Val Accuracy: 1.0000\n",
            "Epoch 9/30, Train Loss: 0.4348, Train Accuracy: 0.9986, Val Loss: 0.4293, Val Accuracy: 1.0000\n",
            "Epoch 10/30, Train Loss: 0.4064, Train Accuracy: 1.0000, Val Loss: 0.3856, Val Accuracy: 1.0000\n",
            "Epoch 11/30, Train Loss: 0.3948, Train Accuracy: 0.9986, Val Loss: 0.3793, Val Accuracy: 1.0000\n",
            "Epoch 12/30, Train Loss: 0.3918, Train Accuracy: 0.9986, Val Loss: 0.3795, Val Accuracy: 1.0000\n",
            "Epoch 13/30, Train Loss: 0.3857, Train Accuracy: 1.0000, Val Loss: 0.3814, Val Accuracy: 1.0000\n",
            "Epoch 14/30, Train Loss: 0.3844, Train Accuracy: 1.0000, Val Loss: 0.3764, Val Accuracy: 1.0000\n",
            "Epoch 15/30, Train Loss: 0.3828, Train Accuracy: 1.0000, Val Loss: 0.3760, Val Accuracy: 1.0000\n",
            "Epoch 16/30, Train Loss: 0.3852, Train Accuracy: 0.9986, Val Loss: 0.3755, Val Accuracy: 1.0000\n",
            "Epoch 17/30, Train Loss: 0.3817, Train Accuracy: 1.0000, Val Loss: 0.3744, Val Accuracy: 1.0000\n",
            "Epoch 18/30, Train Loss: 0.3789, Train Accuracy: 1.0000, Val Loss: 0.3733, Val Accuracy: 1.0000\n",
            "Epoch 19/30, Train Loss: 0.3802, Train Accuracy: 1.0000, Val Loss: 0.3731, Val Accuracy: 1.0000\n",
            "Epoch 20/30, Train Loss: 0.3786, Train Accuracy: 1.0000, Val Loss: 0.3705, Val Accuracy: 1.0000\n",
            "Epoch 21/30, Train Loss: 0.3792, Train Accuracy: 1.0000, Val Loss: 0.3708, Val Accuracy: 1.0000\n",
            "Epoch 22/30, Train Loss: 0.3746, Train Accuracy: 1.0000, Val Loss: 0.3710, Val Accuracy: 1.0000\n",
            "Epoch 23/30, Train Loss: 0.3752, Train Accuracy: 1.0000, Val Loss: 0.3714, Val Accuracy: 1.0000\n",
            "Epoch 24/30, Train Loss: 0.3762, Train Accuracy: 1.0000, Val Loss: 0.3712, Val Accuracy: 1.0000\n",
            "Epoch 25/30, Train Loss: 0.3759, Train Accuracy: 1.0000, Val Loss: 0.3701, Val Accuracy: 1.0000\n",
            "Epoch 26/30, Train Loss: 0.3761, Train Accuracy: 1.0000, Val Loss: 0.3705, Val Accuracy: 1.0000\n",
            "Epoch 27/30, Train Loss: 0.3733, Train Accuracy: 1.0000, Val Loss: 0.3703, Val Accuracy: 1.0000\n",
            "Epoch 28/30, Train Loss: 0.3777, Train Accuracy: 1.0000, Val Loss: 0.3704, Val Accuracy: 1.0000\n",
            "Epoch 29/30, Train Loss: 0.3744, Train Accuracy: 1.0000, Val Loss: 0.3700, Val Accuracy: 1.0000\n",
            "Epoch 30/30, Train Loss: 0.3737, Train Accuracy: 1.0000, Val Loss: 0.3709, Val Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_random_image(image_folder_path):\n",
        "    image_files = [f for f in os.listdir(image_folder_path) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
        "    random_image_path = os.path.join(image_folder_path, random.choice(image_files))\n",
        "    image = Image.open(random_image_path).convert('L')\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "    ])\n",
        "    image = transform(image)\n",
        "    return image\n",
        "\n",
        "def test_random_image(model, image_folder_path):\n",
        "    model.eval()\n",
        "\n",
        "    image = load_random_image(image_folder_path)\n",
        "    image = image.unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "              output = model(image)\n",
        "\n",
        "    _, predicted_class = torch.max(output, 1)\n",
        "    predicted_class = predicted_class.item()\n",
        "\n",
        "    print(f\"Predicted class for the random image: {'Cancer' if predicted_class == 1 else 'No Cancer'}\")\n",
        "\n",
        "image_folder_path = 'output/test/abnormal'\n",
        "test_random_image(model, image_folder_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPcEkeLsVVdW",
        "outputId": "de72ae78-4dff-4350-9bba-3fcae989953b"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class for the random image: Cancer\n"
          ]
        }
      ]
    },
    {
      "source": [
        "model.eval()\n",
        "test_running_loss = 0.0\n",
        "test_correct = 0\n",
        "test_total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for test_inputs, test_labels in test_loader:\n",
        "        test_inputs, test_labels = test_inputs.to(device), test_labels.to(device)\n",
        "\n",
        "        test_outputs = model(test_inputs)\n",
        "\n",
        "        test_loss = criterion(test_outputs, test_labels)\n",
        "\n",
        "        test_running_loss += test_loss.item()\n",
        "        _, test_predicted = torch.max(test_outputs.data, 1)\n",
        "        test_total += test_labels.size(0)\n",
        "        test_correct += (test_predicted == test_labels).sum().item()\n",
        "\n",
        "test_loss_avg = test_running_loss / len(test_loader)\n",
        "test_accuracy = test_correct / test_total\n",
        "\n",
        "print(f\"Test Loss: {test_loss_avg:.4f}, Test Accuracy: {test_accuracy:.4f}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "Niu8f9g1_lHc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a34bb13f-6177-492c-cc5b-769fec165f1e"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.3804, Test Accuracy: 0.9933\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IIw1yER8jjpn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}